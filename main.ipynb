{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exotic-fetish",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convenient-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (0.4.5)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n",
      "Requirement already satisfied: madgrad in /opt/conda/lib/python3.7/site-packages (1.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "\n",
    "!pip install -q -U albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "!pip install madgrad\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "periodic-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'cspdarknet53',\n",
       " 'cspdarknet53_iabn',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'cspresnext50_iabn',\n",
       " 'darknet53',\n",
       " 'densenet121',\n",
       " 'densenet121d',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264',\n",
       " 'densenet264d_iabn',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'ese_vovnet99b_iabn',\n",
       " 'fbnetc_100',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_a1',\n",
       " 'mnasnet_b1',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'nasnetalarge',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f0s',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f1s',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f2s',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f3s',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f4s',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f5s',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f6s',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_f7s',\n",
       " 'nfnet_l0a',\n",
       " 'nfnet_l0b',\n",
       " 'nfnet_l0c',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'seresnet18',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26tn_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_deit_base_distilled_patch16_224',\n",
       " 'vit_deit_base_distilled_patch16_384',\n",
       " 'vit_deit_base_patch16_224',\n",
       " 'vit_deit_base_patch16_384',\n",
       " 'vit_deit_small_distilled_patch16_224',\n",
       " 'vit_deit_small_patch16_224',\n",
       " 'vit_deit_tiny_distilled_patch16_224',\n",
       " 'vit_deit_tiny_patch16_224',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s3_224',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-nevada",
   "metadata": {},
   "source": [
    "### CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focused-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"model\" : \"tf_efficientnet_b4\",\n",
    "    \"pretrained\" : True,\n",
    "    \"drop_rate\" : 0.2,\n",
    "    \"seed\" : 9,\n",
    "    \"img_size\" : (380, 380),\n",
    "    \"crop_size\" : (380, 380),\n",
    "    \"epoch\" : 4,\n",
    "    \"T_0\" : 10,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"min_lr\" : 1e-6,\n",
    "    \"weight_decay\" : 1e-2,\n",
    "    \"train_bs\" : 32,\n",
    "    \"test_bs\" : 32,\n",
    "    \"cross_valid\" : True,\n",
    "    \"k_fold\" : 5,\n",
    "    \"num_workers\" : 8,\n",
    "    \"num_accum\" : 1,\n",
    "    \"num_classes\" : 18,\n",
    "    \"device\" : torch.device(\"cuda\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-printer",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "express-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    \"train\" : A.Compose([\n",
    "#         A.Resize(CFG[\"img_size\"][0], CFG[\"img_size\"][1], p=1.0),\n",
    "        A.CenterCrop(CFG[\"crop_size\"][0], CFG[\"crop_size\"][1], p=1.0),\n",
    "        A.CLAHE(p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),   # 색체 변경\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]),\n",
    "    \"test\" : A.Compose([\n",
    "#         A.Resize(CFG[\"img_size\"][0], CFG[\"img_size\"][1], p=1.0),\n",
    "        A.CenterCrop(CFG[\"crop_size\"][0], CFG[\"crop_size\"][1], p=1.0),\n",
    "        A.CLAHE(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-senegal",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recovered-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)                         # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))    # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removable-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Label Smoothing Loss\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hairy-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- F1 Loss\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-accident",
   "metadata": {},
   "source": [
    "### Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entertaining-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(CFG[\"model\"], pretrained=CFG[\"pretrained\"], num_classes=CFG[\"num_classes\"], drop_rate=CFG[\"drop_rate\"])\n",
    "model.to(CFG[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "# optimizer = MADGRAD(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=CFG[\"T_0\"], eta_min=CFG[\"min_lr\"])\n",
    "criterion = FocalLoss().to(CFG[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-stake",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vertical-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/opt/ml/input/data/train\"\n",
    "test_dir = \"/opt/ml/input/data/eval\"\n",
    "\n",
    "train_csv = os.path.join(train_dir, \"fixed_label.csv\")\n",
    "test_csv = os.path.join(test_dir, \"info.csv\")\n",
    "\n",
    "df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, df, exist_label, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.exist_label = exist_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        if self.exist_label:\n",
    "            target = self.df.iloc[index][\"label\"]       \n",
    "            path = self.df.iloc[index][\"filepath\"]\n",
    "        else:\n",
    "            path = os.path.join(test_dir, \"images\", self.df.iloc[index][\"ImageID\"])\n",
    "            \n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        \n",
    "        if self.exist_label:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-agenda",
   "metadata": {},
   "source": [
    "### Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, iterator):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "       \n",
    "        n_total, n_correct = 0, 0\n",
    "        for batch_data, batch_label in tqdm(iterator):\n",
    "            target = batch_label.to(CFG[\"device\"])\n",
    "            output = model(batch_data.float().to(CFG[\"device\"]))\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "            n_correct += (prediction == target).sum().item()\n",
    "            n_total += batch_data.size(0)\n",
    "        accuracy = n_correct / n_total\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "separate-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_f1_score(model, iterator):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        targets, predictions = [], []\n",
    "        for batch_data, batch_label in tqdm(iterator):\n",
    "            target = batch_label.to(CFG[\"device\"])\n",
    "            output = model(batch_data.float().to(CFG[\"device\"]))\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "            targets += target.tolist()\n",
    "            predictions += prediction.tolist()\n",
    "            \n",
    "    return f1_score(targets, predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-stamp",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experimental-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(CFG, model, criterion, train_iter, optimizer, scheduler):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for j, (batch_data, batch_label) in tqdm(enumerate(train_iter), total=len(train_iter), position=0, leave=True):\n",
    "        target = batch_label.to(CFG[\"device\"])\n",
    "        prediction = model(batch_data.float().to(CFG[\"device\"]))\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient accumulation\n",
    "        if j % CFG[\"num_accum\"] == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "specialized-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(CFG, model, criterion, valid_iter):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for batch_data, batch_label in tqdm(valid_iter):            \n",
    "            target = batch_label.to(CFG[\"device\"])\n",
    "            prediction = model(batch_data.float().to(CFG[\"device\"]))\n",
    "            loss = criterion(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valid-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(CFG, transforms, df, save_path):\n",
    "    groups = [df for _, df in df.groupby(\"id\")]\n",
    "    random.seed(CFG[\"seed\"])\n",
    "    random.shuffle(groups)\n",
    "    df = pd.concat(groups)\n",
    "        \n",
    "    best_score = 0\n",
    "    \n",
    "    train_df = df.iloc[:len(df)*4//5]\n",
    "    valid_df = df.iloc[len(df)*4//5:]\n",
    "    \n",
    "    train_dataset = MaskDataset(train_df, exist_label=True, transforms=transforms[\"train\"])\n",
    "    valid_dataset = MaskDataset(valid_df, exist_label=True, transforms=transforms[\"test\"])\n",
    "\n",
    "    train_iter = DataLoader(dataset=train_dataset, batch_size=CFG[\"train_bs\"], shuffle=True, num_workers=CFG[\"num_workers\"])\n",
    "    valid_iter = DataLoader(dataset=valid_dataset, batch_size=CFG[\"test_bs\"], shuffle=False, num_workers=CFG[\"num_workers\"])\n",
    "\n",
    "    for i in range(CFG[\"epoch\"]):\n",
    "        train_one_epoch(CFG, model, criterion, train_iter, optimizer, scheduler)\n",
    "        valid_one_epoch(CFG, model, criterion, valid_iter)\n",
    "\n",
    "        train_score = eval_f1_score(model, train_iter)\n",
    "        valid_score = eval_f1_score(model, valid_iter)\n",
    "\n",
    "        # save\n",
    "        if valid_score > best_score:            \n",
    "            best_score = valid_score\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, f'{CFG[\"model\"]}.pth'))\n",
    "            print(\"(BEST)\", end=\" \")\n",
    "\n",
    "        print(f'epoch:[{i + 1}/{CFG[\"epoch\"]}] train_score:[{train_score * 100 :.4f}%] valid_score:[{valid_score * 100 :.4f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worth-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid(CFG, transforms, df, save_path):\n",
    "    groups = [df for _, df in df.groupby(\"id\")]\n",
    "    random.seed(CFG[\"seed\"])\n",
    "    random.shuffle(groups)\n",
    "    df = pd.concat(groups)\n",
    "    \n",
    "    total_size = len(df)\n",
    "    fraction = 1 / CFG[\"k_fold\"]\n",
    "    seg = int(total_size * fraction)\n",
    "    # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset \n",
    "    # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
    "    for k in range(CFG[\"k_fold\"]):\n",
    "        model = timm.create_model(CFG[\"model\"], pretrained=CFG[\"pretrained\"], num_classes=CFG[\"num_classes\"], drop_rate=CFG[\"drop_rate\"])\n",
    "        model.to(CFG[\"device\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "#         optimizer = MADGRAD(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=CFG[\"T_0\"], eta_min=CFG[\"min_lr\"])\n",
    "        criterion = FocalLoss().to(CFG[\"device\"])\n",
    "        \n",
    "        best_score = 0\n",
    "        \n",
    "        trll = 0\n",
    "        trlr = k * seg\n",
    "        vall = trlr\n",
    "        valr = k * seg + seg\n",
    "        trrl = valr\n",
    "        trrr = total_size\n",
    "\n",
    "        train_left_df = df.iloc[trll:trlr]\n",
    "        train_right_df = df.iloc[trrl:trrr]\n",
    "        train_df = pd.concat([train_left_df, train_right_df])\n",
    "        valid_df = df.iloc[vall:valr]\n",
    "        \n",
    "        train_dataset = MaskDataset(train_df, exist_label=True, transforms=transforms[\"train\"])\n",
    "        valid_dataset = MaskDataset(valid_df, exist_label=True, transforms=transforms[\"test\"])\n",
    "\n",
    "        train_iter = DataLoader(dataset=train_dataset, batch_size=CFG[\"train_bs\"], shuffle=True, num_workers=CFG[\"num_workers\"])\n",
    "        valid_iter = DataLoader(dataset=valid_dataset, batch_size=CFG[\"test_bs\"], shuffle=False, num_workers=CFG[\"num_workers\"])\n",
    "        \n",
    "        for i in range(CFG[\"epoch\"]):\n",
    "            train_one_epoch(CFG, model, criterion, train_iter, optimizer, scheduler)\n",
    "            valid_one_epoch(CFG, model, criterion, valid_iter)\n",
    "            \n",
    "            train_score = eval_f1_score(model, train_iter)\n",
    "            valid_score = eval_f1_score(model, valid_iter)\n",
    "            \n",
    "            # save\n",
    "            if valid_score > best_score:            \n",
    "                best_score = valid_score\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, f'{CFG[\"model\"]}_[{k}].pth'))\n",
    "                print(\"(BEST)\", end=\" \")\n",
    "                \n",
    "            print(f'k_fold:[{k + 1}/{CFG[\"k_fold\"]}] epoch:[{i + 1}/{CFG[\"epoch\"]}] train_score:[{train_score * 100 :.4f}%] valid_score:[{valid_score * 100 :.4f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compliant-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.89it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.30it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[1/5] epoch:[1/4] train_score:[90.6329%] valid_score:[75.8169%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.86it/s]\n",
      "100%|██████████| 472/472 [01:15<00:00,  6.23it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[1/5] epoch:[2/4] train_score:[95.2375%] valid_score:[75.5610%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.02it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.30it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[1/5] epoch:[3/4] train_score:[94.8334%] valid_score:[77.8881%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  6.99it/s]\n",
      "100%|██████████| 472/472 [01:15<00:00,  6.27it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[1/5] epoch:[4/4] train_score:[96.5762%] valid_score:[76.0713%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.93it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.20it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[2/5] epoch:[1/4] train_score:[90.7701%] valid_score:[75.4932%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.72it/s]\n",
      "100%|██████████| 472/472 [01:18<00:00,  6.05it/s]\n",
      "100%|██████████| 118/118 [00:19<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[2/5] epoch:[2/4] train_score:[92.0098%] valid_score:[73.0843%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.75it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.17it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[2/5] epoch:[3/4] train_score:[94.5287%] valid_score:[75.0079%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.54it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.29it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[2/5] epoch:[4/4] train_score:[98.3643%] valid_score:[76.6938%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  6.96it/s]\n",
      "100%|██████████| 472/472 [01:15<00:00,  6.21it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[3/5] epoch:[1/4] train_score:[90.4338%] valid_score:[76.0538%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.83it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.16it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[3/5] epoch:[2/4] train_score:[96.1384%] valid_score:[74.0988%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.93it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.16it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[3/5] epoch:[3/4] train_score:[97.2409%] valid_score:[74.3679%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.71it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.18it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[3/5] epoch:[4/4] train_score:[97.0087%] valid_score:[74.8914%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  6.96it/s]\n",
      "100%|██████████| 472/472 [01:15<00:00,  6.23it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[4/5] epoch:[1/4] train_score:[89.1658%] valid_score:[73.2715%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:39<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  6.99it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.35it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[4/5] epoch:[2/4] train_score:[93.8203%] valid_score:[76.9679%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:41<00:00,  2.13it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.80it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.29it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[4/5] epoch:[3/4] train_score:[93.7479%] valid_score:[68.3275%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.75it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.14it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[4/5] epoch:[4/4] train_score:[96.5498%] valid_score:[73.6652%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:16<00:00,  7.01it/s]\n",
      "100%|██████████| 472/472 [01:15<00:00,  6.23it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[5/5] epoch:[1/4] train_score:[92.1721%] valid_score:[76.2068%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.74it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.20it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[5/5] epoch:[2/4] train_score:[95.9663%] valid_score:[76.6276%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:40<00:00,  2.15it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.74it/s]\n",
      "100%|██████████| 472/472 [01:16<00:00,  6.20it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold:[5/5] epoch:[3/4] train_score:[93.2236%] valid_score:[74.7978%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 472/472 [03:40<00:00,  2.14it/s]\n",
      "100%|██████████| 118/118 [00:17<00:00,  6.65it/s]\n",
      "100%|██████████| 472/472 [01:14<00:00,  6.35it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) k_fold:[5/5] epoch:[4/4] train_score:[96.5073%] valid_score:[78.6507%]\n",
      "1:50:50\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "save_path = \"/opt/ml/code/checkpoints\"\n",
    "if CFG[\"cross_valid\"]:\n",
    "    cross_valid(CFG, transforms, df, save_path)\n",
    "else:\n",
    "    train(CFG, transforms, df, save_path)\n",
    "print(str(datetime.timedelta(seconds=time.time()-start)).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-expression",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:57<00:00,  6.79it/s]\n",
      " 85%|████████▌ | 336/394 [00:49<00:08,  6.75it/s]"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "\n",
    "test_dataset = MaskDataset(submission, exist_label=False, transforms=transforms[\"test\"])\n",
    "test_iter = DataLoader(test_dataset, batch_size=CFG[\"test_bs\"], shuffle=False, num_workers=CFG[\"num_workers\"])\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "if CFG[\"cross_valid\"]:\n",
    "    for k in range(CFG[\"k_fold\"]):\n",
    "        model.load_state_dict(torch.load(os.path.join(save_path, f'{CFG[\"model\"]}_[{k}].pth')))\n",
    "        model.eval()\n",
    "        temp_predictions = []\n",
    "        for images in tqdm(test_iter):\n",
    "            with torch.no_grad():\n",
    "                output = model(images.float().to(CFG[\"device\"]))\n",
    "                temp_predictions.extend(output.cpu().numpy())   \n",
    "        all_predictions.append(temp_predictions)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(os.path.join(save_path, f'{CFG[\"model\"]}.pth')))\n",
    "    model.eval()\n",
    "    temp_predictions = []\n",
    "    for images in tqdm(test_iter):\n",
    "        with torch.no_grad():\n",
    "            output = model(images.float().to(CFG[\"device\"]))\n",
    "            temp_predictions.extend(output.cpu().numpy())   \n",
    "    all_predictions.append(temp_predictions)\n",
    "    \n",
    "all_predictions = np.array(all_predictions)\n",
    "all_predictions = all_predictions.sum(axis=0)\n",
    "all_predictions = all_predictions.argmax(axis=-1)\n",
    "            \n",
    "submission['ans'] = all_predictions\n",
    "# submission.to_csv(f'/opt/ml/code/submissions/test_lsloss.csv', index=False)\n",
    "submission.to_csv(f'/opt/ml/code/submissions/final_{CFG[\"model\"]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-still",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
